{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A model outputs logits.\n",
    "- In multi-class segmentation tasks, usually the models outputs a tensor with shape [C, H, W], where C is the number of classes (background included) and where each channel is a sort of binary segmentation for the objects of that class. Every \"pixel\" has a higher logit in the channel of the class it probably belongs, and a lower logits in all the other channels, for it is less likely the \"pixel\" belongs to those classes. (This is a bit redundant in binary segmentation tasks because there are only two classes, background and object).\n",
    "- There are logits also in the channel for the background class.\n",
    "- To be confronted with the GT, which can be seen as a one-hot encoded probability distribution along the classes for each pixel, these logits are turned into a probability distribution, AKA into probs between 0 and 1. The Sigmoid is used in binary segmentation cases, while the Softmax in used in multi-class segmentation cases.\n",
    "- No threshold is applied before computing the loss (whatever loss it is). The threshold is applied when we want to see the prediction, so we turn the logits into probs again, apply the threshold, thus turning the pred to boolean and then plot it.\n",
    "- Binary Cross-Entropy is just a sub-type of Cross-Entropy: there are just two classes.\n",
    "- Both CE anb BCE need the predictions to be as probabilities, that is the sum over the classes must be 1. In reality many implementation take logits but that's because a Softmax (for CE) or a Sigmoid (for BCE) is applied internally.\n",
    "- For cross-entropy loss, the position of the pixels doesn't matter: it's as if a flattening in performed on the image turning it into a vector.\n",
    "- Interesting source: https://gombru.github.io/2018/05/23/cross_entropy_loss/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> CROSS-ENTROPY LOSS FOR SEGMENTATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(pred, true):\n",
    "    \"\"\"\n",
    "    Compute Cross-Entropy loss on predicted logits for a single example for an image segmentation task.\n",
    "      \n",
    "    Pred can either:\n",
    "    1) consist of as many channels as number of classes, thus having shape (C, H, W), being\n",
    "    C the number of classes (including background). In this case the function computes standard \n",
    "    cross-entropy loss and a softmax activation function is applied across classes.\n",
    "    2) have shape (H, W), thus being a case of binary segmentation. In this case the function\n",
    "    computes binary cross-entropy, thus needing a sigmoid activation function, which is applied.\n",
    "    \n",
    "    Args:\n",
    "        pred (torch.tensor): model prediction as logits. \n",
    "        true (torch.tensor): target with shape (H, W), each pixel having an integer ID\n",
    "            label indicating the class it belongs to.\n",
    "        \n",
    "    Returns:\n",
    "        Cross-Entropy loss value.\n",
    "    \"\"\"\n",
    "\n",
    "    n_classes = len(torch.unique(true)) # background is counted as a class\n",
    "    height = pred.shape[-2]\n",
    "    width = pred.shape[-1]\n",
    "\n",
    "    # If there are only two classes, it's a binary segmentatio problem,\n",
    "    # so the sigmoid should be used as activation function to turn logits into probs.\n",
    "    if n_classes == 2:\n",
    "        activation_function = torch.nn.Sigmoid()\n",
    "        # Add channel dimension also to pred\n",
    "        pred = pred.unsqueeze(0) # shape = [C, H, W] = [1, H, W]\n",
    "       \n",
    "    # If there are more than two classes, it's a multi-class segmentation problem,\n",
    "    # so the softmax should be used as activation function to turn logits into probs.\n",
    "    elif n_classes > 2:\n",
    "        activation_function = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    # Convert to required type\n",
    "    pred = pred.type(torch.float32)\n",
    "    true = true.type(torch.int64)\n",
    "    \n",
    "    # Turn GT mask to one-hot-encoding,\n",
    "    # with as many channels as number of classes, \n",
    "    # where every channel is a sort of a binary segmentation mask with\n",
    "    # the objects of that class.\n",
    "    true_ohe = torch.nn.functional.one_hot(true, num_classes=n_classes).permute(2, 0, 1) # shape = [C, H, W]\n",
    "      \n",
    "    # Basically in the computation of the CE loss for image segmentation,\n",
    "    # each pixel of the prediction is a probability distribution along the\n",
    "    # channels, that is along the classes. This vector is compared to the target\n",
    "    # prob distribution (one-hot encoded) by calculating the CE loss with the\n",
    "    # standard formula. The CE losses of all the pixels are then averaged to\n",
    "    # get the final CE loss for that image.\n",
    "    \n",
    "    # # # MULTICLASS SEGMENTATION\n",
    "    if n_classes > 2: \n",
    "        pixel_losses = []\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                # Get logits of the pixel along the channels/classes.\n",
    "                pixel_i_pred_logits = pred[..., i, j] # shape = [n_classes]\n",
    "                # Use softmax to turn the logits into a probability distribution along the classes.\n",
    "                pixel_i_pred_probs = activation_function(pixel_i_pred_logits) # shape = [n_classes]\n",
    "                # Remove zeros otherwise later matrix multiplication error.\n",
    "                pixel_i_pred_probs = torch.where(pixel_i_pred_probs == 0., 1e-8, pixel_i_pred_probs)\n",
    "                # Get GT probability distribution.\n",
    "                pixel_i_true_probs = true_ohe[..., i, j].type(torch.float32) # shape = [n_classes]\n",
    "                # Turn both pred and true to matrix with shape (1, n_classes), \n",
    "                # to perform the matrix multiplication.\n",
    "                pixel_i_pred_probs = pixel_i_pred_probs.unsqueeze(0) # shape = [1, n_classes]\n",
    "                pixel_i_true_probs = pixel_i_true_probs.unsqueeze(0) # shape = [1, n_classes]\n",
    "                # Compute Cross-Entropy loss for the single pixel.\n",
    "                pixel_i_loss = -torch.matmul(\n",
    "                    torch.log(pixel_i_pred_probs),\n",
    "                    pixel_i_true_probs.T # transpose to change shape to [n_classes, 1]\n",
    "                )\n",
    "                pixel_losses.append(pixel_i_loss.item())\n",
    "                \n",
    "    # # # BINARY SEGMENTATION\n",
    "    if n_classes == 2:\n",
    "        pixel_losses = []\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                # Get logit of the pixel\n",
    "                pixel_i_pred_logit = pred[..., i, j] # shape = [1]\n",
    "                # Use sigmoid to turn the logit into a prob.\n",
    "                pixel_i_pred_prob = activation_function(pixel_i_pred_logit) # shape = [1]\n",
    "                # Transform in a tensor with the prob of belonging to background and\n",
    "                # prob of belonging to an object.\n",
    "                pixel_i_pred_probs = torch.cat((1. - pixel_i_pred_prob, pixel_i_pred_prob)) # shape = [2]\n",
    "                # Remove zeros otherwise later matrix multiplication error.\n",
    "                pixel_i_pred_probs = torch.where(pixel_i_pred_probs == 0., 1e-8, pixel_i_pred_probs)\n",
    "                # Get GT probability distribution.\n",
    "                pixel_i_true_probs = true_ohe[..., i, j].type(torch.float32) # shape = [2]\n",
    "                # Turn both pred and true to matrix with shape (1, n_classes), \n",
    "                # to perform the matrix multiplication.\n",
    "                pixel_i_pred_probs = pixel_i_pred_probs.unsqueeze(0) # shape = [1, 2]\n",
    "                pixel_i_true_probs = pixel_i_true_probs.unsqueeze(0) # shape = [1, 2]\n",
    "                # Compute Cross-Entropy loss for the single pixel.\n",
    "                pixel_i_loss = -torch.matmul(\n",
    "                    torch.log(pixel_i_pred_probs), \n",
    "                    pixel_i_true_probs.T # transpose to change shape to [2, 1]\n",
    "                )\n",
    "                pixel_losses.append(pixel_i_loss.item())\n",
    "        \n",
    "    # The CE loss for the image is the average of the CE losses of all its pixels.\n",
    "    loss = np.round(np.mean(pixel_losses), 3).item()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR BINARY SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([5, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GT\n",
    "true = torch.tensor([\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 1],\n",
    "    [1, 1, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1]\n",
    "])\n",
    "\n",
    "# Prediction by a model (logits)\n",
    "pred = torch.tensor([\n",
    "    [-0.9833, -0.7652, -0.7690,  1.5309, -2.4188],\n",
    "    [ 0.8150, -1.1432,  1.3916, -0.1599, -0.9577],\n",
    "    [ 0.8008, -0.6601, -0.6325, -0.3961,  1.4413],\n",
    "    [ 0.5683,  1.3544, -0.2154,  0.5649,  1.3917],\n",
    "    [-0.5142, -2.0285, -2.2410, -0.6006, -0.1540]\n",
    "])\n",
    "\n",
    "true.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAACgCAYAAABqgSVVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAADEklEQVR4nO3asUkkQACG0dlDU7EEe7AZIwsQLEEQizBxEwObsAYT7URjcS4+juNbOJ2Vu/figX/cXT4mcDPnnAOAP/qx7wsAfHdCCRCEEiAIJUAQSoAglABBKAGCUAKEg10Pbjabr7zHb/wf/Of717/D8/PzpXtHR0dL9z4+PpbujTHG7e3t0r3v+hv1ogQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgbOacc6eDm81X3+UXO17r06z++/Zh9We62svLy9K96+vrpXsPDw9L98YYY7vdLt17enpaund/f7/TOS9KgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAcLBrgfnnF95D/hrq3+jJycnS/eurq6W7o0xxvHx8dK97Xa7dG9XXpQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECAf7vsD/bM657yv8U15fX5fu3dzcLN27u7tbujfGGKenp0v33t/fl+4dHh7udM6LEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoBwsO8LwGd5fHxcund2drZ07+3tbeneGGNcXFws3Xt+fl66d3l5udM5L0qAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBwmbOOfd9CYDvzIsSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiD8BMKET9bSckWLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots(nrows=1, ncols=2, figsize=(4, 2))\n",
    "axis[0].imshow(true, cmap='gray')\n",
    "axis[0].axis('off')\n",
    "axis[1].imshow(pred, cmap='gray')\n",
    "axis[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary cross-entropy by PyTorch\n",
    "bce_loss_pytorch = torch.nn.BCEWithLogitsLoss()\n",
    "bce_loss_pytorch(input=pred, target=true.float()).numpy().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary cross-entropy by my function\n",
    "bce = cross_entropy_loss(pred=pred, true=true)\n",
    "bce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR MULTI-CLASS SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([4, 5, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GT, with 4 classes (background included)\n",
    "true = torch.tensor([\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 3],\n",
    "    [2, 2, 0, 0, 3],\n",
    "    [2, 2, 0, 3, 3],\n",
    "    [2, 2, 0, 3, 3]\n",
    "])\n",
    "\n",
    "# Pred\n",
    "torch.manual_seed(42)\n",
    "pred = torch.randn(size=(4, 5, 5))\n",
    "\n",
    "true.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.386"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-entropy by PyTorch\n",
    "\n",
    "# By Piotr Bialecki:\n",
    "# Expects the model output to have shape [batch_size, nb_classes, height, width] and\n",
    "# the target [batch_size, height, width], containing the class indices in the \n",
    "# range [0, nb_classes-1].\n",
    "\n",
    "ce_loss_pytorch = torch.nn.CrossEntropyLoss()\n",
    "ce_loss_pytorch (pred[None, ...], true[None, ...]).numpy().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.386"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-entropy by my function\n",
    "ce = cross_entropy_loss(pred=pred, true=true)\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053\n",
      "0.053\n"
     ]
    }
   ],
   "source": [
    "# Simulating a very good prediction by a model: loss should be close to 0.\n",
    "x = 2. # higher --> the more perfect the prediction is.\n",
    "\n",
    "pred = torch.cat([\n",
    "    torch.where(true == 0., x, -x)[None, ...],\n",
    "    torch.where(true == 1., x, -x)[None, ...],\n",
    "    torch.where(true == 2., x, -x)[None, ...],\n",
    "    torch.where(true == 3., x, -x)[None, ...],\n",
    "])\n",
    "\n",
    "print(ce_loss_pytorch(pred[None, ...], true[None, ...]).numpy().round(3))\n",
    "print(cross_entropy_loss(pred, true))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZED AND WEIGHTED VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class WeightedCrossEntropyLoss(torch.nn.Module):\n",
    "    '''A PyTorch Module for computing weighted cross entropy loss.\n",
    "    \n",
    "    Args:\n",
    "        class_weights: A tensor with class weights.    \n",
    "    '''\n",
    "    def __init__(self, class_weights: Optional[torch.Tensor]=None) -> None:\n",
    "        super().__init__()\n",
    "        self.activation = torch.nn.Softmax(dim=1)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        '''Computes the weighted cross-entropy loss between the input and target.\n",
    "    \n",
    "        Args:\n",
    "            input: A tensor with model logits. Required shape [batch size, n classes, H, W]. \n",
    "            target: A tensor with GT one-hot-encoded. Required shape [batch size, n classes, H, W].\n",
    "                \n",
    "        Returns:\n",
    "            torch.Tensor: A scalar tensor representing the computed weighted cross-entropy loss for the input batch,\n",
    "            as average on all pixel losses.\n",
    "        \n",
    "        '''\n",
    "        input_activated = self.activation(input)\n",
    "        input_activated = torch.where(input_activated == 0., torch.tensor(1e-8), input_activated)\n",
    "        pixel_losses = -torch.sum(target * torch.log(input_activated), dim=1) # shape = [H, W]\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            weighted_pixel_losses = target * self.class_weights.view(1, -1, 1, 1) # basically the target tensor with class weights instead of ones.\n",
    "            weighted_pixel_losses = torch.sum(weighted_pixel_losses, dim=1) # basically the mask [H, W] with class indexes but with the weights.\n",
    "            pixel_losses = pixel_losses * weighted_pixel_losses # weight every pixel loss.\n",
    "        \n",
    "        batch_loss = torch.mean(pixel_losses) # batch loss as average over all pixel losses\n",
    "        \n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ohe = torch.nn.functional.one_hot(true, num_classes=4).permute(2, 0, 1) # shape = [C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss = WeightedCrossEntropyLoss()\n",
    "ce_loss(pred[None, ...], true_ohe[None, ...]).numpy().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss = WeightedCrossEntropyLoss(class_weights=torch.tensor([0.0, 0.5, 0.3, 0.2]).to(pred.device))\n",
    "ce_loss(pred[None, ...], true_ohe[None, ...]).numpy().round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The preferred format for the weights is with range [0, 1].\n",
    "- If we use fraction weights [0, 1] (as above) or integer weights [0, +inf] with equivalent proportions, the results will not be the same, contrary to what one may expect. This is because of how the weights are multiplied to the CE formula.\n",
    "- In a nutshell, when weights are integers, we are multiplying the loss of the different classes by different coeffiecients. When the weights are fractions, we are reducing the loss of each class by different percentages: some classes are reduce more, other less.\n",
    "- Only numbers change, while the reciprocal relation between classes is the same for integers or fraction weights.\n",
    "- Remember: the value of the loss means nothing, it is the difference between consecutive losses to matter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> CROSS-ENTROPY LOSS FOR CLASSIFICATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR MULTI-CLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(543)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "preds = torch.randn(size=(3, 5), dtype=torch.float32) # 3 is number of data examples, 5 is the number of classes.\n",
    "targets = torch.empty(3, dtype=torch.long).random_(5) # long type required by one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3])\n",
      "torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape, targets.shape)\n",
    "print(preds.dtype, targets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9000,  1.0630,  0.1354, -0.3442,  1.4945],\n",
       "        [-1.9455, -2.0836,  0.8109, -0.3634,  0.4801],\n",
       "        [ 0.7173,  0.4489, -1.6775, -0.7023,  0.3009]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions as logits.\n",
    "preds\n",
    "\n",
    "# Each row is a single example and the columns are the logits\n",
    "# for each one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GTs as class ID each example belongs to.\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GTs one-hot-encoded.\n",
    "targets_ohe = torch.nn.functional.one_hot(targets, num_classes=5).type(torch.float32)\n",
    "targets_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4445)\n",
      "tensor(2.4445)\n"
     ]
    }
   ],
   "source": [
    "# Cross-entropy loss by PyTorch for the batch of data.\n",
    "crossent = torch.nn.CrossEntropyLoss()\n",
    "print(crossent(preds, targets))\n",
    "print(crossent(preds, targets_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4445"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basically the loss is computed for each example separately, then averaged.\n",
    "losses = []\n",
    "for i in range(len(preds)):\n",
    "    loss = crossent(preds[i], targets[i])\n",
    "    losses.append(loss.item())\n",
    "\n",
    "np.mean(losses).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1360, 0.7637, 2.4338])\n"
     ]
    }
   ],
   "source": [
    "# Cross-entropy loss from scratch.\n",
    "n_data = len(targets)\n",
    "single_losses = []\n",
    "\n",
    "for i in range(n_data):\n",
    "    # Take gt and prediction of single example.\n",
    "    true = targets_ohe[i]\n",
    "    pred = preds[i]\n",
    "    # Turn to matrix with shape (1, 5), to be able to\n",
    "    # do the matrix multiplication.\n",
    "    true = true.unsqueeze(0)\n",
    "    pred = pred.unsqueeze(0)\n",
    "    # Turn pred logits to range [0, 1] with softmax.\n",
    "    pred_soft = torch.softmax(pred, dim=1)\n",
    "    # Compute cross entropy loss for single example.\n",
    "    loss = -torch.matmul(\n",
    "        torch.log(pred_soft), # shape (1, 5)\n",
    "        true.T # transpose to change shape to (5, 1)\n",
    "    )\n",
    "    single_losses.append(loss.item())\n",
    "\n",
    "single_losses = torch.tensor(single_losses)\n",
    "print(single_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The final loss, that is the loss for the batch, is the mean of the single losses.\n",
    "batch_loss = single_losses.mean().numpy().round(4)\n",
    "batch_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR BINARY CLASSIFICATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When there are just two classes: 0 and 1.\n",
    "- In binary classification problems, the activation function is the Sigmoid function: a function that converts any real-valued scalar to a point in the interval [0, 1].\n",
    "- In binary classification problems we have two classes: Class-A and Not-Class-A --> 1 for Class-A and 0 for Not-Class-A.\n",
    "- The model, for a given example, returns a logit for its belonging to Class-A. The Sigmoid function turns the logit into a [0, 1] value, that can be seen as the probability to belong to Class-A (p). Consequently, the probability to belong to Not-Class-A is 1-p.\n",
    "- The Softmax for binary classification problem cannot be used because it requires a vector of values. In binary classification problems, for a single example, with have just 1 value (the logit), while in multi-class classification problems, for a single example, we have multiple values (logits), that is a vector of values, one for each one of the classes. For this reason it makes sense to use the Softmax for multi-class classification problems.\n",
    "- Quote from Wiki: _\"The softmax function converts a vector of K real numbers into a probability distribution of K possible outcomes.\"_.\n",
    "- The Softmax can be seen as an extension of the Sigmoid, or in another perspective it can be demonstrated that the Sigmoid is a special case of the Softmax, where there are just two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "bce = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random generation with seed\n",
    "torch.manual_seed(1888)\n",
    "n_examples = 7\n",
    "preds = torch.randn(n_examples)\n",
    "targets = torch.empty(n_examples).random_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5843, -0.0216, -1.1199, -0.6197,  0.2238, -0.3295, -1.5031])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logits, AKA scores for class belonging (more understandable as probabilities...)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1700, 0.4900, 0.2500, 0.3500, 0.5600, 0.4200, 0.1800])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pred as probabilities\n",
    "# for each example, it's the probability to belong to class 1\n",
    "# Since for binary classification problems the chosen activation function is the Sigmoid,\n",
    "# the sum doesn't add to 1, and that's correct because every value belong to a different\n",
    "# example and their sum being 1 makes no sense (it makes sense in multi-class classification\n",
    "# problems where the probs of each class for a single example should add up to 1).\n",
    "preds_probs = sigmoid(preds)\n",
    "preds_probs = torch.round(preds_probs, decimals=2)\n",
    "preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets, that is true class for each example.\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8633)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary Cross-Entropy\n",
    "loss = bce(preds_probs, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2108)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the preds were closer to the targets, loss would have been lower.\n",
    "# (Ignore the fact that those preds are clearly not coming from a softmax...)\n",
    "bce(\n",
    "    input = torch.tensor([0.8, 0.9, 0.2, 0.1, 0.7, 0.3, 0.9]),\n",
    "    target = targets\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to compute it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0., 0., 1., 0., 1.])\n",
      "\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode targets.\n",
    "# If target_i has class \"0\" it means that is 1 for class \"0\" and 0 for class \"1\".\n",
    "targets_ohe = torch.nn.functional.one_hot(targets.long(), num_classes=2).type(torch.float32)\n",
    "\n",
    "print(targets)\n",
    "print()\n",
    "print(targets_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1700, 0.4900, 0.2500, 0.3500, 0.5600, 0.4200, 0.1800])\n",
      "\n",
      "tensor([0.8300, 0.5100, 0.7500, 0.6500, 0.4400, 0.5800, 0.8200])\n",
      "\n",
      "tensor([[0.8300, 0.1700],\n",
      "        [0.5100, 0.4900],\n",
      "        [0.7500, 0.2500],\n",
      "        [0.6500, 0.3500],\n",
      "        [0.4400, 0.5600],\n",
      "        [0.5800, 0.4200],\n",
      "        [0.8200, 0.1800]])\n",
      "\n",
      "torch.Size([7, 2])\n"
     ]
    }
   ],
   "source": [
    "### Turn preds into matrix\n",
    "\n",
    "# Original preds: probability to belong to class 1\n",
    "class_1_probs = preds_probs.clone()\n",
    "print(class_1_probs)\n",
    "print()\n",
    "\n",
    "# Probability to belong to class 0\n",
    "class_0_probs = torch.ones(size=class_1_probs.shape)\n",
    "class_0_probs = class_0_probs - preds_probs\n",
    "print(class_0_probs)\n",
    "print()\n",
    "\n",
    "# Build matrix \n",
    "preds_matrix = torch.stack([class_0_probs, class_1_probs], dim=1)\n",
    "print(preds_matrix)\n",
    "print()\n",
    "\n",
    "# Still 7 examples and 2 classes\n",
    "print(preds_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8633"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BCE from scratch, which is the same as the Cross-Entropy from scrath above.\n",
    "n_data = len(preds_matrix)\n",
    "single_losses = []\n",
    "\n",
    "for i in range(n_data):\n",
    "    # Take gt and prediction of single example.\n",
    "    true = targets_ohe[i]\n",
    "    pred = preds_matrix[i]\n",
    "    # Turn to matrix with shape (1, 2), to be able to\n",
    "    # do the matrix multiplication.\n",
    "    true = true.unsqueeze(0)\n",
    "    pred = pred.unsqueeze(0)\n",
    "    # Turn pred logits to range [0, 1] with softmax.\n",
    "    # pred_soft = torch.softmax(pred, dim=1)\n",
    "    # Compute cross entropy loss for single example.\n",
    "    loss = -torch.matmul(\n",
    "        torch.log(pred), # shape (1, 5)\n",
    "        true.T # transpose to change shape to (5, 1)\n",
    "    )\n",
    "    single_losses.append(loss.item())\n",
    "\n",
    "single_losses = torch.tensor(single_losses)\n",
    "batch_loss = single_losses.mean().numpy().round(4)\n",
    "batch_loss    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR CLASSIFICATION: Here is how to decide whether to apply sigmoid or softmax to the raw output values from your network:\n",
    "\n",
    "-   If you have a multi-label classification problem = there is more than one \"right answer\" = the outputs are NOT mutually exclusive, then use a sigmoid function on each raw output independently. The sigmoid will allow you to have high probability for all of your classes, some of them, or none of them. Example: classifying diseases in a chest x-ray image. The image might contain pneumonia, emphysema, and/or cancer, or none of those findings.\n",
    "\n",
    "-   If you have a multi-class classification problem = there is only one \"right answer\" = the outputs are mutually exclusive, then use a softmax function. The softmax will enforce that the sum of the probabilities of your output classes are equal to one, so in order to increase the probability of a particular class, your model must correspondingly decrease the probability of at least one of the other classes. Example: classifying images from the MNIST data set of handwritten digits. A single picture of a digit has only one true identity - the picture cannot be a 7 and an 8 at the same time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> SOFTMAX VS SIGMOID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([-2.54, 4.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0731, 0.9837])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = torch.nn.Sigmoid()\n",
    "sigmoid(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0013, 0.9987])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=0)\n",
    "softmax(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0731])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(torch.tensor([-2.54]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(torch.tensor([-2.54]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid works indipendentely on each value, while the softmax works on the series of values as a whole and the sum of the result is 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
